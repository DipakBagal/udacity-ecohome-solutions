{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfd641d",
   "metadata": {},
   "source": [
    "# EcoHome RAG Setup\n",
    "## Set up Retrieval-Augmented Generation (RAG) with ChromaDB\n",
    "\n",
    "This notebook:\n",
    "1. Loads energy-saving documents from the knowledge base\n",
    "2. Splits documents into chunks for embedding\n",
    "3. Creates embeddings using OpenAI\n",
    "4. Stores embeddings in ChromaDB vector database\n",
    "5. Tests retrieval with sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"✗ Error: OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Please set your OpenAI API key in .env file\")\n",
    "else:\n",
    "    print(\"✓ OpenAI API key found\")\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b66c5",
   "metadata": {},
   "source": [
    "## Step 1: Load Knowledge Base Documents\n",
    "\n",
    "Load all text documents from the data/documents/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up document loader\n",
    "documents_path = \"./data/documents/\"\n",
    "\n",
    "print(f\"Loading documents from: {os.path.abspath(documents_path)}\")\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    documents_path,\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Load documents\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(documents)} documents\")\n",
    "print(\"\\nDocuments:\")\n",
    "for doc in documents:\n",
    "    source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "    filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1]\n",
    "    print(f\"  - {filename}: {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86e0ce",
   "metadata": {},
   "source": [
    "## Step 2: Split Documents into Chunks\n",
    "\n",
    "Split long documents into smaller chunks for better retrieval and embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03bd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Maximum chunk size\n",
    "    chunk_overlap=200,      # Overlap between chunks\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Split on paragraphs, then sentences\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "print(\"Splitting documents into chunks...\")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"✓ Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nAverage chunk size: {sum(len(chunk.page_content) for chunk in chunks) / len(chunks):.0f} characters\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0].page_content[:500] + \"...\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ac1d4",
   "metadata": {},
   "source": [
    "## Step 3: Create Embeddings and Vector Store\n",
    "\n",
    "Generate embeddings for all chunks and store them in ChromaDB for fast retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998195a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings model\n",
    "print(\"Initializing OpenAI embeddings...\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "print(\"✓ Embeddings model initialized\")\n",
    "\n",
    "# Set up ChromaDB directory\n",
    "chroma_db_path = \"./chroma_db\"\n",
    "print(f\"\\nCreating vector store at: {os.path.abspath(chroma_db_path)}\")\n",
    "\n",
    "# Create vector store\n",
    "print(\"\\nGenerating embeddings and building vector store...\")\n",
    "print(\"(This may take a minute for large knowledge bases)\")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=chroma_db_path\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Vector store created with {len(chunks)} embedded chunks\")\n",
    "print(f\"✓ Persisted to: {os.path.abspath(chroma_db_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2add652",
   "metadata": {},
   "source": [
    "## Step 4: Test Retrieval\n",
    "\n",
    "Test the RAG system with sample queries to verify it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"How can I reduce my HVAC energy costs?\",\n",
    "    \"What are the best practices for EV charging?\",\n",
    "    \"How do I optimize my solar battery storage?\",\n",
    "    \"What are good energy-saving tips for summer?\"\n",
    "]\n",
    "\n",
    "print(\"Testing retrieval with sample queries...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Search for relevant documents\n",
    "    results = vector_store.similarity_search(query, k=2)\n",
    "    \n",
    "    print(f\"Found {len(results)} relevant results:\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        source = result.metadata.get(\"source\", \"Unknown\")\n",
    "        filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1]\n",
    "        \n",
    "        print(f\"{i}. From: {filename}\")\n",
    "        print(f\"   Content: {result.page_content[:300]}...\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✓ Retrieval tests complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcb9b7",
   "metadata": {},
   "source": [
    "## Step 5: Test with Similarity Search and Scores\n",
    "\n",
    "Test retrieval with similarity scores to understand relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bb717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with scores\n",
    "test_query = \"How to save energy with smart home automation?\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Search with scores\n",
    "results_with_scores = vector_store.similarity_search_with_score(test_query, k=3)\n",
    "\n",
    "print(f\"\\nTop 3 Results with Similarity Scores:\\n\")\n",
    "\n",
    "for i, (result, score) in enumerate(results_with_scores, 1):\n",
    "    source = result.metadata.get(\"source\", \"Unknown\")\n",
    "    filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1]\n",
    "    \n",
    "    print(f\"{i}. Relevance Score: {score:.4f}\")\n",
    "    print(f\"   Source: {filename}\")\n",
    "    print(f\"   Content Preview:\")\n",
    "    print(f\"   {result.page_content[:400]}...\")\n",
    "    print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"\\n✓ Note: Lower scores indicate higher similarity/relevance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e55aeed",
   "metadata": {},
   "source": [
    "## Step 6: Verify Vector Store Persistence\n",
    "\n",
    "Verify that the vector store was saved and can be reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf21fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that ChromaDB was persisted\n",
    "print(\"Verifying vector store persistence...\\n\")\n",
    "\n",
    "if os.path.exists(chroma_db_path):\n",
    "    print(f\"✓ Vector store directory exists: {os.path.abspath(chroma_db_path)}\")\n",
    "    \n",
    "    # List files in directory\n",
    "    files = os.listdir(chroma_db_path)\n",
    "    print(f\"\\nFiles in vector store:\")\n",
    "    for file in files:\n",
    "        file_path = os.path.join(chroma_db_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  - {file}: {size:,} bytes\")\n",
    "    \n",
    "    # Test reloading\n",
    "    print(\"\\nTesting vector store reload...\")\n",
    "    reloaded_store = Chroma(\n",
    "        persist_directory=chroma_db_path,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    \n",
    "    # Test query on reloaded store\n",
    "    test_results = reloaded_store.similarity_search(\"solar panels\", k=1)\n",
    "    print(f\"✓ Successfully reloaded vector store\")\n",
    "    print(f\"✓ Verified with test query - found {len(test_results)} result(s)\")\n",
    "else:\n",
    "    print(f\"✗ Error: Vector store directory not found at {os.path.abspath(chroma_db_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1b6b0",
   "metadata": {},
   "source": [
    "## Step 7: RAG System Statistics\n",
    "\n",
    "Display summary statistics about the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d3473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "total_chars = sum(len(doc.page_content) for doc in documents)\n",
    "total_words = sum(len(doc.page_content.split()) for doc in documents)\n",
    "avg_chunk_chars = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)\n",
    "avg_chunk_words = sum(len(chunk.page_content.split()) for chunk in chunks) / len(chunks)\n",
    "\n",
    "print(\"RAG System Statistics\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nKnowledge Base:\")\n",
    "print(f\"  Documents: {len(documents)}\")\n",
    "print(f\"  Total characters: {total_chars:,}\")\n",
    "print(f\"  Total words: {total_words:,}\")\n",
    "print(f\"  Average document size: {total_chars // len(documents):,} characters\")\n",
    "\n",
    "print(f\"\\nChunking:\")\n",
    "print(f\"  Total chunks: {len(chunks)}\")\n",
    "print(f\"  Average chunk size: {avg_chunk_chars:.0f} characters ({avg_chunk_words:.0f} words)\")\n",
    "print(f\"  Chunk overlap: 200 characters\")\n",
    "\n",
    "print(f\"\\nVector Store:\")\n",
    "print(f\"  Database: ChromaDB\")\n",
    "print(f\"  Location: {os.path.abspath(chroma_db_path)}\")\n",
    "print(f\"  Embeddings: OpenAI (text-embedding-ada-002)\")\n",
    "print(f\"  Embedded chunks: {len(chunks)}\")\n",
    "\n",
    "print(f\"\\nUsage:\")\n",
    "print(f\"  The RAG system is now ready for use by the EcoHome agent\")\n",
    "print(f\"  It will automatically search these {len(chunks)} chunks to answer questions\")\n",
    "print(f\"  Average retrieval: 2-3 most relevant chunks per query\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ RAG setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2360c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "RAG system has been successfully set up with:\n",
    "- All knowledge base documents loaded and embedded\n",
    "- ChromaDB vector store created and persisted\n",
    "- Retrieval tested and verified working\n",
    "- System ready for use by the EcoHome agent\n",
    "\n",
    "The vector store is now available for:\n",
    "- The `search_energy_tips` tool in tools.py\n",
    "- The EcoHome agent to provide informed recommendations\n",
    "- Direct queries for energy-saving information\n",
    "\n",
    "Next steps:\n",
    "1. Run `03_run_and_evaluate.ipynb` to test the complete agent system"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
