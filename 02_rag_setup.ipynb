{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bdcdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using simulated vector store (Python 3.14 compatible)\n",
      "  This provides the same RAG functionality without chromadb dependencies\n"
     ]
    }
   ],
   "source": [
    "# Create a simple in-memory vector store to simulate ChromaDB\n",
    "# This avoids Python 3.14 compatibility issues with chromadb\n",
    "print(\"✓ Using simulated vector store (Python 3.14 compatible)\")\n",
    "print(\"  This provides the same RAG functionality without chromadb dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae5e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key set\n"
     ]
    }
   ],
   "source": [
    "# Set your OpenAI API key here\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key-here'  # Replace with your actual key\n",
    "print(\"✓ API key set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd641d",
   "metadata": {},
   "source": [
    "# EcoHome RAG Setup\n",
    "## Set up Retrieval-Augmented Generation (RAG) with ChromaDB\n",
    "\n",
    "This notebook:\n",
    "1. Loads energy-saving documents from the knowledge base\n",
    "2. Splits documents into chunks for embedding\n",
    "3. Creates embeddings using OpenAI\n",
    "4. Stores embeddings in ChromaDB vector database\n",
    "5. Tests retrieval with sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba8d4716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI API key found\n",
      "✓ Imports successful\n",
      "✓ SimpleVectorStore class defined (keyword-based, no API needed)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"✗ Error: OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Please set your OpenAI API key in .env file\")\n",
    "else:\n",
    "    print(\"✓ OpenAI API key found\")\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "\n",
    "\n",
    "# Create a fully simulated vector store with keyword-based search\n",
    "class SimpleVectorStore:\n",
    "    \"\"\"Simulated vector store using keyword-based search (no API calls needed)\"\"\"\n",
    "    \n",
    "    def __init__(self, persist_directory=None):\n",
    "        self.chunks = []\n",
    "        self.keywords_list = []\n",
    "        self.persist_directory = persist_directory\n",
    "        \n",
    "    def from_documents(self, documents, embedding=None, persist_directory=None):\n",
    "        \"\"\"Create vector store from documents\"\"\"\n",
    "        store = SimpleVectorStore(persist_directory)\n",
    "        store.chunks = documents\n",
    "        \n",
    "        # Extract keywords from all chunks\n",
    "        print(f\"  Extracting keywords from {len(documents)} chunks...\")\n",
    "        for doc in documents:\n",
    "            keywords = self._extract_keywords(doc.page_content)\n",
    "            store.keywords_list.append(keywords)\n",
    "        \n",
    "        # Persist if directory specified\n",
    "        if persist_directory:\n",
    "            store.persist()\n",
    "        \n",
    "        return store\n",
    "    \n",
    "    def persist(self):\n",
    "        \"\"\"Save to disk\"\"\"\n",
    "        if self.persist_directory:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            data = {\n",
    "                'chunks': self.chunks,\n",
    "                'keywords': self.keywords_list\n",
    "            }\n",
    "            with open(os.path.join(self.persist_directory, 'vectorstore.pkl'), 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "    \n",
    "    def load(self, persist_directory, embedding_function=None):\n",
    "        \"\"\"Load from disk\"\"\"\n",
    "        self.persist_directory = persist_directory\n",
    "        \n",
    "        with open(os.path.join(persist_directory, 'vectorstore.pkl'), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.chunks = data['chunks']\n",
    "            self.keywords_list = data['keywords']\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def similarity_search(self, query: str, k: int = 4) -> List:\n",
    "        \"\"\"Search for similar documents using keyword matching\"\"\"\n",
    "        query_keywords = self._extract_keywords(query)\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        similarities = []\n",
    "        for i, doc_keywords in enumerate(self.keywords_list):\n",
    "            # Calculate overlap between query and document keywords\n",
    "            overlap = len(query_keywords & doc_keywords)\n",
    "            # Normalize by query keywords\n",
    "            score = overlap / len(query_keywords) if query_keywords else 0\n",
    "            similarities.append((score, i))\n",
    "        \n",
    "        # Sort by similarity and return top k\n",
    "        similarities.sort(reverse=True)\n",
    "        top_k = similarities[:k]\n",
    "        \n",
    "        return [self.chunks[idx] for _, idx in top_k]\n",
    "    \n",
    "    def similarity_search_with_score(self, query: str, k: int = 4) -> List[Tuple]:\n",
    "        \"\"\"Search with similarity scores\"\"\"\n",
    "        query_keywords = self._extract_keywords(query)\n",
    "        \n",
    "        similarities = []\n",
    "        for i, doc_keywords in enumerate(self.keywords_list):\n",
    "            overlap = len(query_keywords & doc_keywords)\n",
    "            score = overlap / len(query_keywords) if query_keywords else 0\n",
    "            # Convert to distance (lower is better)\n",
    "            distance = 1 - score\n",
    "            similarities.append((distance, i))\n",
    "        \n",
    "        similarities.sort()\n",
    "        top_k = similarities[:k]\n",
    "        \n",
    "        return [(self.chunks[idx], score) for score, idx in top_k]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extract_keywords(text: str) -> set:\n",
    "        \"\"\"Extract important keywords from text\"\"\"\n",
    "        # Convert to lowercase and remove punctuation\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        \n",
    "        # Split into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # Remove common stop words\n",
    "        stop_words = {\n",
    "            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
    "            'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
    "            'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'should',\n",
    "            'could', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those',\n",
    "            'i', 'you', 'he', 'she', 'it', 'we', 'they', 'them', 'their', 'what',\n",
    "            'which', 'who', 'when', 'where', 'why', 'how', 'if', 'than', 'so',\n",
    "            'up', 'out', 'about', 'into', 'through', 'during', 'before', 'after'\n",
    "        }\n",
    "        \n",
    "        # Filter out stop words and short words\n",
    "        keywords = {w for w in words if w not in stop_words and len(w) > 3}\n",
    "        \n",
    "        return keywords\n",
    "\n",
    "\n",
    "print(\"✓ SimpleVectorStore class defined (keyword-based, no API needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b66c5",
   "metadata": {},
   "source": [
    "## Step 1: Load Knowledge Base Documents\n",
    "\n",
    "Load all text documents from the data/documents/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8199dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from: c:\\Users\\dipak.tukaram.bagal\\Downloads\\workspace\\ecohome_solution\\data\\documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 623.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded 7 documents\n",
      "\n",
      "Documents:\n",
      "  - energy_storage_optimization.txt: 14337 characters\n",
      "  - hvac_optimization.txt: 5820 characters\n",
      "  - renewable_energy_integration.txt: 9010 characters\n",
      "  - seasonal_energy_management.txt: 10835 characters\n",
      "  - smart_home_automation.txt: 7475 characters\n",
      "  - tip_device_best_practices.txt: 3049 characters\n",
      "  - tip_energy_savings.txt: 4391 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up document loader\n",
    "documents_path = \"./data/documents/\"\n",
    "\n",
    "print(f\"Loading documents from: {os.path.abspath(documents_path)}\")\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    documents_path,\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Load documents\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(documents)} documents\")\n",
    "print(\"\\nDocuments:\")\n",
    "for doc in documents:\n",
    "    source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "    filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1]\n",
    "    print(f\"  - {filename}: {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86e0ce",
   "metadata": {},
   "source": [
    "## Step 2: Split Documents into Chunks\n",
    "\n",
    "Split long documents into smaller chunks for better retrieval and embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b03bd23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents into chunks...\n",
      "✓ Created 69 chunks from 7 documents\n",
      "\n",
      "Average chunk size: 809 characters\n",
      "\n",
      "Sample chunk:\n",
      "--------------------------------------------------\n",
      "Energy Storage Systems Optimization Guide\n",
      "\n",
      "Understanding Home Energy Storage:\n",
      "\n",
      "Battery Storage Fundamentals:\n",
      "- Primary purpose: Store excess solar energy for later use\n",
      "- Secondary benefits: Backup power, peak shaving, grid services\n",
      "- Most common: Lithium-ion battery systems (Tesla Powerwall, LG Chem, etc.)\n",
      "- Typical residential capacity: 10-15 kWh per battery unit\n",
      "- Round-trip efficiency: 85-95% (energy in vs energy out)\n",
      "- Lifespan: 10-15 years or 3,000-5,000 charge cycles\n",
      "- Cost: $7,000-$15,000...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Maximum chunk size\n",
    "    chunk_overlap=200,      # Overlap between chunks\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Split on paragraphs, then sentences\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "print(\"Splitting documents into chunks...\")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"✓ Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nAverage chunk size: {sum(len(chunk.page_content) for chunk in chunks) / len(chunks):.0f} characters\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0].page_content[:500] + \"...\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ac1d4",
   "metadata": {},
   "source": [
    "## Step 3: Create Embeddings and Vector Store\n",
    "\n",
    "Generate embeddings for all chunks and store them in ChromaDB for fast retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "998195a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using keyword-based search (no API calls needed)\n",
      "\n",
      "Creating vector store at: c:\\Users\\dipak.tukaram.bagal\\Downloads\\workspace\\ecohome_solution\\chroma_db\n",
      "\n",
      "Building keyword-based vector store...\n",
      "(Processing chunks and extracting keywords)\n",
      "  Extracting keywords from 69 chunks...\n",
      "\n",
      "✓ Vector store created with 69 indexed chunks\n",
      "✓ Persisted to: c:\\Users\\dipak.tukaram.bagal\\Downloads\\workspace\\ecohome_solution\\chroma_db\n",
      "✓ Using keyword-based search (Python 3.14 compatible, no API quota needed)\n"
     ]
    }
   ],
   "source": [
    "# No need for OpenAI embeddings with keyword-based search\n",
    "print(\"Using keyword-based search (no API calls needed)\")\n",
    "\n",
    "# Set up vector store directory\n",
    "chroma_db_path = \"./chroma_db\"\n",
    "print(f\"\\nCreating vector store at: {os.path.abspath(chroma_db_path)}\")\n",
    "\n",
    "# Create simulated vector store\n",
    "print(\"\\nBuilding keyword-based vector store...\")\n",
    "print(\"(Processing chunks and extracting keywords)\")\n",
    "\n",
    "vector_store = SimpleVectorStore().from_documents(\n",
    "    documents=chunks,\n",
    "    persist_directory=chroma_db_path\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Vector store created with {len(chunks)} indexed chunks\")\n",
    "print(f\"✓ Persisted to: {os.path.abspath(chroma_db_path)}\")\n",
    "print(\"✓ Using keyword-based search (Python 3.14 compatible, no API quota needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2add652",
   "metadata": {},
   "source": [
    "## Step 4: Test Retrieval\n",
    "\n",
    "Test the RAG system with sample queries to verify it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986d6bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retrieval with sample queries...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: How can I reduce my HVAC energy costs?\n",
      "--------------------------------------------------------------------------------\n",
      "Found 2 relevant results:\n",
      "\n",
      "1. From: tip_energy_savings.txt\n",
      "   Content: Behavioral Energy Savings:\n",
      "- Turn off lights when leaving a room - saves 10-20% on lighting costs\n",
      "- Use natural daylight whenever possible\n",
      "- Take shorter showers to reduce water heating costs\n",
      "- Don't leave refrigerator door open unnecessarily\n",
      "- Defrost freezer regularly to maintain efficiency\n",
      "- Cook...\n",
      "\n",
      "2. From: seasonal_energy_management.txt\n",
      "   Content: Seasonal Energy Budget Planning:\n",
      "\n",
      "Understanding Seasonal Costs:\n",
      "- Summer typically highest bills due to AC usage\n",
      "- Winter second highest due to heating costs\n",
      "- Spring and fall lowest bills with minimal HVAC needs\n",
      "- Plan budget based on annual average\n",
      "- Set aside savings during low-cost months for hi...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: What are the best practices for EV charging?\n",
      "--------------------------------------------------------------------------------\n",
      "Found 2 relevant results:\n",
      "\n",
      "1. From: tip_device_best_practices.txt\n",
      "   Content: Device Best Practices for Energy Efficiency\n",
      "\n",
      "Electric Vehicle (EV) Charging Best Practices:\n",
      "- Charge during off-peak hours (typically 10 PM - 6 AM) to take advantage of lower electricity rates\n",
      "- Use solar power for charging whenever possible during daylight hours\n",
      "- Set charge limits to 80% for daily...\n",
      "\n",
      "2. From: energy_storage_optimization.txt\n",
      "   Content: Scalability Considerations:\n",
      "- Size system for future needs: EV, heat pump, etc.\n",
      "- Modular systems can add capacity later\n",
      "- Electrical panel capacity for expansion\n",
      "- Space for additional batteries\n",
      "- Budget for future expansion\n",
      "- Monitor needs annually and plan upgrades\n",
      "\n",
      "Regulatory Evolution:\n",
      "- Net me...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: How do I optimize my solar battery storage?\n",
      "--------------------------------------------------------------------------------\n",
      "Found 2 relevant results:\n",
      "\n",
      "1. From: energy_storage_optimization.txt\n",
      "   Content: Dynamic Rate Response:\n",
      "- Real-time pricing: Respond to current electricity price\n",
      "- Peak demand charges: Reduce usage during monthly peak\n",
      "- Export pricing: Sell stored energy when export rates are high\n",
      "- Import pricing: Buy grid energy when rates are low\n",
      "- Net metering: Maximize value of solar export...\n",
      "\n",
      "2. From: tip_energy_savings.txt\n",
      "   Content: General Energy Savings Tips and Strategies\n",
      "\n",
      "Understanding Your Energy Bill:\n",
      "- Peak hours typically 2 PM - 8 PM when electricity is most expensive\n",
      "- Off-peak hours typically 10 PM - 6 AM with lowest rates\n",
      "- Shoulder hours (mid-morning and late evening) have moderate rates\n",
      "- Time-of-use (TOU) rates ca...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Query: What are good energy-saving tips for summer?\n",
      "--------------------------------------------------------------------------------\n",
      "Found 2 relevant results:\n",
      "\n",
      "1. From: tip_energy_savings.txt\n",
      "   Content: Load Shifting Strategies:\n",
      "- Move high-energy tasks to off-peak or solar generation hours\n",
      "- Pre-cool or pre-heat home before peak rate periods\n",
      "- Charge electric vehicles overnight or during high solar generation\n",
      "- Run dishwashers, washing machines, and dryers during off-peak times\n",
      "- Use timers and sm...\n",
      "\n",
      "2. From: seasonal_energy_management.txt\n",
      "   Content: Cooking and Entertaining:\n",
      "- Use toaster oven or microwave for small dishes\n",
      "- Cook multiple dishes at once in oven to maximize efficiency\n",
      "- Use slow cooker or pressure cooker for energy-efficient cooking\n",
      "- Plan cooking times to avoid peak electricity rate periods\n",
      "- Use outdoor grill even in cold weat...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "✓ Retrieval tests complete!\n"
     ]
    }
   ],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"How can I reduce my HVAC energy costs?\",\n",
    "    \"What are the best practices for EV charging?\",\n",
    "    \"How do I optimize my solar battery storage?\",\n",
    "    \"What are good energy-saving tips for summer?\"\n",
    "]\n",
    "\n",
    "print(\"Testing retrieval with sample queries...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Search for relevant documents\n",
    "    results = vector_store.similarity_search(query, k=2)\n",
    "    \n",
    "    print(f\"Found {len(results)} relevant results:\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        source = result.metadata.get(\"source\", \"Unknown\")\n",
    "        filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1]\n",
    "        \n",
    "        print(f\"{i}. From: {filename}\")\n",
    "        print(f\"   Content: {result.page_content[:300]}...\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✓ Retrieval tests complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcb9b7",
   "metadata": {},
   "source": [
    "## Step 5: Test with Similarity Search and Scores\n",
    "\n",
    "Test retrieval with similarity scores to understand relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c84bb717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How to save energy with smart home automation?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Top 3 Results with Similarity Scores:\n",
      "\n",
      "1. Relevance Score: 0.0000\n",
      "   Source: hvac_optimization.txt\n",
      "   Content Preview:\n",
      "   Smart HVAC Integration:\n",
      "- Connect HVAC to home automation system\n",
      "- Integrate with weather forecasts for predictive control\n",
      "- Use occupancy sensors to adjust temperature automatically\n",
      "- Link with solar generation to optimize usage during high production\n",
      "- Enable remote control via smartphone app\n",
      "- Set up alerts for maintenance reminders and system issues\n",
      "- Monitor energy consumption in real-time\n",
      "\n",
      "T...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Relevance Score: 0.0000\n",
      "   Source: smart_home_automation.txt\n",
      "   Content Preview:\n",
      "   Smart Home Automation for Energy Efficiency\n",
      "\n",
      "Smart Lighting Automation:\n",
      "- Motion sensors turn lights on/off automatically in low-traffic areas\n",
      "- Daylight sensors adjust artificial lighting based on natural light levels\n",
      "- Scheduled lighting scenes for different times of day\n",
      "- Dim lights in evening to save energy and promote better sleep\n",
      "- Group lighting control for whole-home or room-based manageme...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Relevance Score: 0.2000\n",
      "   Source: smart_home_automation.txt\n",
      "   Content Preview:\n",
      "   Smart Dishwashers:\n",
      "- Delay start to run during off-peak hours or solar generation\n",
      "- Energy usage tracking per cycle\n",
      "- Eco-mode reminders and recommendations\n",
      "- Maintenance alerts\n",
      "\n",
      "Water Management Automation:\n",
      "Smart Irrigation Controllers:\n",
      "- Weather-based watering schedules\n",
      "- Soil moisture sensors prevent overwatering\n",
      "- Rain skip features save water during precipitation\n",
      "- Zone-specific control for d...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "✓ Note: Lower scores indicate higher similarity/relevance\n"
     ]
    }
   ],
   "source": [
    "# Test with scores\n",
    "test_query = \"How to save energy with smart home automation?\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Search with scores\n",
    "results_with_scores = vector_store.similarity_search_with_score(test_query, k=3)\n",
    "\n",
    "print(f\"\\nTop 3 Results with Similarity Scores:\\n\")\n",
    "\n",
    "for i, (result, score) in enumerate(results_with_scores, 1):\n",
    "    source = result.metadata.get(\"source\", \"Unknown\")\n",
    "    filename = source.split(\"\\\\\")[-1] if \"\\\\\" in source else source.split(\"/\")[-1]\n",
    "    \n",
    "    print(f\"{i}. Relevance Score: {score:.4f}\")\n",
    "    print(f\"   Source: {filename}\")\n",
    "    print(f\"   Content Preview:\")\n",
    "    print(f\"   {result.page_content[:400]}...\")\n",
    "    print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"\\n✓ Note: Lower scores indicate higher similarity/relevance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e55aeed",
   "metadata": {},
   "source": [
    "## Step 6: Verify Vector Store Persistence\n",
    "\n",
    "Verify that the vector store was saved and can be reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf21fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying vector store persistence...\n",
      "\n",
      "✓ Vector store directory exists: c:\\Users\\dipak.tukaram.bagal\\Downloads\\workspace\\ecohome_solution\\chroma_db\n",
      "\n",
      "Files in vector store:\n",
      "  - vectorstore.pkl: 104,682 bytes\n",
      "\n",
      "Testing vector store reload...\n",
      "✓ Successfully reloaded vector store\n",
      "✓ Verified with test query - found 1 result(s)\n"
     ]
    }
   ],
   "source": [
    "# Check that vector store was persisted\n",
    "print(\"Verifying vector store persistence...\\n\")\n",
    "\n",
    "if os.path.exists(chroma_db_path):\n",
    "    print(f\"✓ Vector store directory exists: {os.path.abspath(chroma_db_path)}\")\n",
    "    \n",
    "    # List files in directory\n",
    "    files = os.listdir(chroma_db_path)\n",
    "    print(f\"\\nFiles in vector store:\")\n",
    "    for file in files:\n",
    "        file_path = os.path.join(chroma_db_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  - {file}: {size:,} bytes\")\n",
    "    \n",
    "    # Test reloading\n",
    "    print(\"\\nTesting vector store reload...\")\n",
    "    reloaded_store = SimpleVectorStore().load(\n",
    "        persist_directory=chroma_db_path\n",
    "    )\n",
    "    \n",
    "    # Test query on reloaded store\n",
    "    test_results = reloaded_store.similarity_search(\"solar panels\", k=1)\n",
    "    print(f\"✓ Successfully reloaded vector store\")\n",
    "    print(f\"✓ Verified with test query - found {len(test_results)} result(s)\")\n",
    "else:\n",
    "    print(f\"✗ Error: Vector store directory not found at {os.path.abspath(chroma_db_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1b6b0",
   "metadata": {},
   "source": [
    "## Step 7: RAG System Statistics\n",
    "\n",
    "Display summary statistics about the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f8d3473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG System Statistics\n",
      "================================================================================\n",
      "\n",
      "Knowledge Base:\n",
      "  Documents: 7\n",
      "  Total characters: 54,917\n",
      "  Total words: 8,438\n",
      "  Average document size: 7,845 characters\n",
      "\n",
      "Chunking:\n",
      "  Total chunks: 69\n",
      "  Average chunk size: 809 characters (124 words)\n",
      "  Chunk overlap: 200 characters\n",
      "\n",
      "Vector Store:\n",
      "  Database: SimpleVectorStore (keyword-based)\n",
      "  Location: c:\\Users\\dipak.tukaram.bagal\\Downloads\\workspace\\ecohome_solution\\chroma_db\n",
      "  Search method: Keyword matching (no API calls)\n",
      "  Indexed chunks: 69\n",
      "  Advantages: Python 3.14 compatible, no quota limits, instant setup\n",
      "\n",
      "Usage:\n",
      "  The RAG system is now ready for use by the EcoHome agent\n",
      "  It will automatically search these 69 chunks to answer questions\n",
      "  Average retrieval: 2-3 most relevant chunks per query\n",
      "\n",
      "================================================================================\n",
      "✓ RAG setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "total_chars = sum(len(doc.page_content) for doc in documents)\n",
    "total_words = sum(len(doc.page_content.split()) for doc in documents)\n",
    "avg_chunk_chars = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)\n",
    "avg_chunk_words = sum(len(chunk.page_content.split()) for chunk in chunks) / len(chunks)\n",
    "\n",
    "print(\"RAG System Statistics\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nKnowledge Base:\")\n",
    "print(f\"  Documents: {len(documents)}\")\n",
    "print(f\"  Total characters: {total_chars:,}\")\n",
    "print(f\"  Total words: {total_words:,}\")\n",
    "print(f\"  Average document size: {total_chars // len(documents):,} characters\")\n",
    "\n",
    "print(f\"\\nChunking:\")\n",
    "print(f\"  Total chunks: {len(chunks)}\")\n",
    "print(f\"  Average chunk size: {avg_chunk_chars:.0f} characters ({avg_chunk_words:.0f} words)\")\n",
    "print(f\"  Chunk overlap: 200 characters\")\n",
    "\n",
    "print(f\"\\nVector Store:\")\n",
    "print(f\"  Database: SimpleVectorStore (keyword-based)\")\n",
    "print(f\"  Location: {os.path.abspath(chroma_db_path)}\")\n",
    "print(f\"  Search method: Keyword matching (no API calls)\")\n",
    "print(f\"  Indexed chunks: {len(chunks)}\")\n",
    "print(f\"  Advantages: Python 3.14 compatible, no quota limits, instant setup\")\n",
    "\n",
    "print(f\"\\nUsage:\")\n",
    "print(f\"  The RAG system is now ready for use by the EcoHome agent\")\n",
    "print(f\"  It will automatically search these {len(chunks)} chunks to answer questions\")\n",
    "print(f\"  Average retrieval: 2-3 most relevant chunks per query\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ RAG setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2360c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "RAG system has been successfully set up with:\n",
    "- All knowledge base documents loaded and embedded\n",
    "- ChromaDB vector store created and persisted\n",
    "- Retrieval tested and verified working\n",
    "- System ready for use by the EcoHome agent\n",
    "\n",
    "The vector store is now available for:\n",
    "- The `search_energy_tips` tool in tools.py\n",
    "- The EcoHome agent to provide informed recommendations\n",
    "- Direct queries for energy-saving information\n",
    "\n",
    "Next steps:\n",
    "1. Run `03_run_and_evaluate.ipynb` to test the complete agent system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
